# Manipula√ß√£o de Dados - Ouro

## Introdu√ß√£o

Neste laborat√≥rio focado na *Camada Ouro*, vamos empregar visualiza√ß√µes tempor√°rias no Spark para efetuar manipula√ß√µes e an√°lises avan√ßadas de dados.

Inicialmente, as visualiza√ß√µes tempor√°rias s√£o criadas para permitir a execu√ß√£o de consultas SQL sobre os DataFrames. Essas visualiza√ß√µes s√£o *n√£o-persistentes* e existem apenas durante a sess√£o do Spark, servindo como uma ponte entre o processamento de dados em Spark e t√©cnicas de banco de dados relacional.

Ao usar visualiza√ß√µes tempor√°rias, os cientistas e engenheiros de dados podem aplicar consultas SQL complexas e manipula√ß√µes de dados sem a necessidade de converter DataFrames em tabelas permanentes. Isso fornece um m√©todo poderoso e flex√≠vel para analisar grandes volumes de dados, aproveitando a facilidade e familiaridade da linguagem SQL.

Uma vez que as manipula√ß√µes e an√°lises s√£o conclu√≠das no Spark, os dados podem ser preparados e exportados para sistemas de armazenamentos de dados como nosso OCI Object Storage (Data Store) e depois podemos acessar esses dados de diversas formas

*Tempo estimado para o Lab:* 15 Minutos

### Objetivos

* Utilizar visualiza√ß√µes tempor√°rias no Spark para consultas SQL em DataFrames.
* Converter DataFrames em tabelas externas para an√°lise em ferramentas como DBeaver.
* Analisar rela√ß√µes comerciais do Brasil com outros pa√≠ses, focando em produtos, estados e meios de transporte em 2023.
* Executar joins complexos para enriquecer dados e realizar an√°lises detalhadas.

## Tarefa 1: Organiza√ß√£o de Tabelas em Star Schema

### *Porque utilizar Star Schema?*

---

O "Star Schema" (Esquema Estrela) √© uma forma de organizar bases de dados especialmente √∫til para armaz√©ns de dados (data warehouses) e an√°lise de dados. Para explic√°-lo de forma intuitiva, vamos usar analogias.

Imagine um supermercado. No centro desse supermercado, voc√™ tem uma grande se√ß√£o de produtos (como frutas, legumes, carnes, etc.), que √© o cora√ß√£o do estabelecimento. Essa se√ß√£o central √© como a tabela de fatos no Star Schema. A tabela de fatos cont√©m informa√ß√µes essenciais, como vendas, transa√ß√µes ou eventos. No caso do supermercado, seriam as vendas di√°rias dos produtos.

Agora, ao redor dessa se√ß√£o central, existem v√°rias outras se√ß√µes menores - como uma para utens√≠lios dom√©sticos, outra para produtos de limpeza, etc. Estas se√ß√µes s√£o como as tabelas de dimens√µes no Star Schema. Cada tabela de dimens√£o cont√©m detalhes sobre um aspecto particular dos dados na tabela de fatos. Por exemplo, uma tabela de dimens√£o pode detalhar informa√ß√µes sobre os clientes, outra sobre os produtos, outra sobre o tempo (data e hora), e assim por diante.

O motivo pelo qual se utiliza o Star Schema √© sua simplicidade e efici√™ncia. Assim como √© mais f√°cil para voc√™ encontrar produtos em um supermercado bem organizado, com se√ß√µes claramente definidas, tamb√©m √© mais f√°cil para os analistas de dados extrair e analisar informa√ß√µes de um banco de dados organizado em Star Schema. Este formato facilita a visualiza√ß√£o das rela√ß√µes entre diferentes tipos de dados e melhora o desempenho das consultas, o que √© crucial para a an√°lise r√°pida e eficaz de grandes volumes de dados.

![Star Schema](.\images\1-star-schema.png)


Inicialmente, iremos obter as tabelas da camada prata salvas no bucket para prosseguir com nossas an√°lises.

1. Selecione a c√©lula e execute-a com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebook.

    ![Leitura Parquet Prata](.\images\2-read-parquet-silver.png)

2. Selecione a c√©lula e execute-a com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebook.

No c√≥digo abaixo, criamos uma de uma nova coluna denominada *`CO_NCM_2_DIG`*. Esta nova coluna √© criada pela extra√ß√£o dos dois primeiros caracteres da coluna *`CO_NCM`* e ser√° utilizada para a uni√£o do dataset principal *`df_exp`* e o dataset *`df_ncm`* que apresenta o nome dos produtos que est√£o codificados.

![Criar Coluna](.\images\3-create-columns.png)

Em seguida, criamos as tabelas atrav√©s da organiza√ß√£o em Star Schema. Inicialmente, temos a tabela fato. Ela cont√©m informa√ß√µes chave como ano, m√™s, unidade, estado, quantidade estat√≠stica, peso l√≠quido, valor FOB e os c√≥digos das tabelas dimensionais. A tabela fato √© o n√∫cleo do Star Schema, armazenando dados transacionais ou m√©tricas de desempenho.

![Criar Tabela Fato Exp](.\images\4-exp-fact-table.png)

Ent√£o criamos as tabelas dimensionais. Essas tabelas fornecem contexto adicional para os dados na tabela fato.

A primeira tabela dimensional, *`df_pais_dim`*, cont√©m detalhes dos pa√≠ses, como nome e c√≥digo do pa√≠s. Esta tabela √© criada unindo *`df_exp_ncm`* com *`df_paises_prata`*, selecionando o nome e o c√≥digo do pa√≠s e eliminando duplicatas.

![Criar Tabela Pa√≠s Dim](.\images\5-pais-dim-table.png)

A segunda tabela dimensional, *`df_via_dim`*, cont√©m informa√ß√µes sobre as vias, como o nome e c√≥digo da via. Ela √© formada unindo *`df_exp_ncm`* com *`df_via_prata`*, selecionando o nome e o c√≥digo da via e, novamente, eliminando duplicatas.

![Criar Tabela Via Dim](.\images\6-via-dim-table.png)

A terceira tabela dimensional, *`df_product_dim`*, cont√©m informa√ß√µes sobre as os produtos, como o nome e c√≥digo dos produtos. Ela √© formada unindo *`df_exp_ncm`* com *`df_ncm_prata`*, selecionando o nome e o c√≥digo do produto e, novamente, eliminando duplicatas.

![Criar Tabela Product Dim](.\images\7-product-dim-table.png)

Posteriormente, salvamos as tabelas Delta para a camada Gold, pois esses dados ser√£o usados para preencher as tabelas externas. Estas tabelas, com suas estruturas definidas, estar√£o dispon√≠veis no DBeaver para an√°lises futuras.

![Salvar Delta Gold](.\images\8-delta-gold.png)

## Tarefa 2: Leitura Parquet Prata e Cria√ß√£o de Visualiza√ß√£o Tempor√°ria - SQL

O c√≥digo abaixo gera uma visualiza√ß√£o tempor√°ria para cada tabela que iremos utilizar. Essas visualiza√ß√µes tempor√°rias funcionam como tabelas virtuais que permitem a execu√ß√£o de consultas SQL sobre os DataFrames. Elas s√£o √∫teis para realizar an√°lises de dados e manipula√ß√µes complexas usando a linguagem SQL, em vez de m√©todos espec√≠ficos de DataFrame do Spark.

1. Selecione a c√©lula e execute-a com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebook.

![Visualiza√ß√£o tempor√°ria](.\images\9-temp-view.png)

> Os comandos s√£o prefixados com *`%%spark -c sql`*, indicando que est√£o sendo executados em um contexto SQL do Apache Spark.

O c√≥digo em seguida mostra a execu√ß√£o de uma consulta SQL para descrever a estrutura de uma visualiza√ß√£o ou DataFrame chamado *`df_exp`*. O comando *`DESCRIBE df_exp`*; √© usado para exibir informa√ß√µes sobre as colunas da visualiza√ß√£o ou DataFrame, como o nome da coluna (col\_name) e o tipo de dados (data\_type) de cada coluna.

1. Selecione a c√©lula e execute-a com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebook.

    ![Visualiza√ß√£o Estrutura](.\images\10-describe-exp.png)

## Tarefa 3: Cria√ß√£o de Database

No primeiro comando, *`CREATE DATABASE LIVELABS_OURO`*, est√° sendo criada uma nova base de dados chamada *`LIVELABS_OURO`*. Este √© um passo t√≠pico no gerenciamento de bancos de dados onde se estabelece um novo cont√™iner l√≥gico no qual tabelas, vistas, procedimentos armazenados e outros objetos de banco de dados ser√£o armazenados.

No segundo comando, *`USE LIVELABS_OURO`*, o sistema est√° sendo instru√≠do a utilizar a base de dados *`LIVELABS_OURO`* que acabou de ser criada. Este comando √© utilizado para definir o contexto de banco de dados para as opera√ß√µes subsequentes, ou seja, qualquer comando SQL executado ap√≥s este comando ser√° aplicado dentro da base de dados *`LIVELABS_OURO`*, at√© que outro comando *`USE`* seja emitido para mudar o contexto para outra base de dados.

1. Selecione a c√©lula e execute-a com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebook.

    ![Cria√ß√£o de Database](.\images\11-create-database.png)

## Tarefa 4: Cria√ß√£o de Nova Coluna e Join de Tabelas

O c√≥digo abaixo cria ou atualiza uma visualiza√ß√£o tempor√°ria chamada *`df_exp_ncm`*. A visualiza√ß√£o √© definida para incluir todas as colunas do DataFrame original *`df_exp`*, al√©m de uma nova coluna denominada *`CO_NCM_2_DIG`*. Esta nova coluna √© criada pela extra√ß√£o dos dois primeiros caracteres da coluna *`CO_NCM`*. Esta nova coluna ser√° utilizada para a uni√£o do dataset principal *`df_exp`* e o dataset *`df_ncm`* que apresenta o nome dos produtos que est√£o codificados.

1. Selecione a c√©lula e execute-a com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebook.

    ![Cria√ß√£o de Coluna](.\images\12-ncm-substring.png)

O c√≥digo abaixo √© uma instru√ß√£o para criar ou atualizar uma visualiza√ß√£o tempor√°ria chamada *`df_exp_enriched`*. Esta visualiza√ß√£o √© composta pela jun√ß√£o de v√°rias tabelas ou DataFrames: *`df_exp_ncm`*, *`df_paises`*, *`df_via`*, e *`df_ncm`*. A cl√°usula SELECT DISTINCT √© usada para selecionar registros √∫nicos de uma combina√ß√£o das colunas especificadas de diferentes tabelas.

A sele√ß√£o obt√©m o nome do pa√≠s (*`NO_PAIS`*) de *`df_paises`*, o modo de transporte (*`NO_VIA`*) de *`df_via`*, e o c√≥digo SH2 (*`NO_SH2_POR`*), renomeado como *`NO_PRODUCT`*, de *`df_ncm`*. Adicionalmente, todas as colunas da visualiza√ß√£o *`df_exp_ncm`* s√£o inclu√≠das na sele√ß√£o (indicado por *`df_exp_ncm.*`*).

As jun√ß√µes entre as tabelas s√£o realizadas da seguinte forma:

- *`df_exp_ncm.CO_PAIS`* √© unido com *`df_paises.CO_PAIS`*
- *`df_exp_ncm.CO_VIA`* √© unido com *`df_via.CO_VIA`*
- *`df_exp_ncm.CO_NCM_2_DIG`* √© unido com *`df_ncm.CO_SH2`*

A visualiza√ß√£o resultante *`df_exp_enriched`* proporciona uma vis√£o enriquecida dos dados, combinando informa√ß√µes de m√∫ltiplas fontes para an√°lises mais complexas dos dados de exporta√ß√£o.


2. Selecione a c√©lula e execute-a com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebook.

    ![Uni√£o de Tabelas](.\images\13-join-tables.png)

Nesta c√©lula, demonstramos o resultado em uma consulta SQL que recupera as primeiras tr√™s linhas da visualiza√ß√£o *`df_exp_enriched`*. Esta visualiza√ß√£o √© o produto da uni√£o das tabelas ou DataFrames, conforme detalhado em comandos anteriores.

3. Selecione a c√©lula e execute-a com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebookS.

    ![Visualizar Uni√£o](.\images\14-visualize-join.png)

## Tarefa 5: Cria√ß√£o de External Tables

Os c√≥digos abaixo demostram uma s√©rie de instru√ß√µes SQL para criar tabelas externas no metastore e inserir dados nelas a partir de uma visualiza√ß√£o enriquecida.

Mas antes vammos entender *`O que √© uma tabela externa?`*

Uma tabela externa em arquitetura de lakehouse refere-se a dados armazenados externamente ao sistema de gerenciamento de dados, como em um data lake. Essa abordagem permite a an√°lise de dados heterog√™neos sem a necessidade de mov√™-los para um armazenamento interno, promovendo flexibilidade e efici√™ncia na gest√£o de grandes volumes de dados.

Este c√≥digo est√° configurando vari√°veis no ambiente Spark para que possam ser utilizadas posteriormente. Ao definir *`bucket_ouro`* e *`namespace`*, voc√™ est√° dizendo ao Spark onde armazenar ou buscar dados e como identificar esse conjunto de dados espec√≠fico. Pense nisso como definir endere√ßos de armazenamento e etiquetas de identifica√ß√£o que ser√£o usados em consultas SQL dentro do Spark. Isso √© necess√°rio para que, quando voc√™ executar consultas SQL que referenciam essas configura√ß√µes, o Spark saiba exatamente onde encontrar os dados que voc√™ est√° pedindo.

![SQL Spark Vari√°veis](.\images\15-variables-spark-sql.png)

Para a tabela *`Fato_Exportacao`*, √© criada uma tabela externa com v√°rias colunas de tipos de dados espec√≠ficos, como STRING e FLOAT. A localiza√ß√£o da tabela √© especificada atrav√©s de um caminho em um bucket, indicando onde os dados da tabela ser√£o armazenados fisicamente.

1. Selecione a c√©lula e execute-a com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebook.

    ![Tabela Externa Exporta√ß√£o](.\images\16-external-table-fato.png)

O mesmo processo √© aplicado para as tabelas *`Dim_Pais`*, *`Dim_Via`* e *`Dim_Product`*, onde cada uma √© criada como uma tabela externa com suas respectivas colunas, e em seguida, s√£o populadas com dados da visualiza√ß√£o *`df_exp_enriched`*.

> Perceba que estamos utilizando as vari√°veis *`bucket_ouro`* e *`namespace`*, que foram configuradas na c√©lula anterior.

2. Selecione cada c√©lula e execute-as com o comando SHIFT + ENTER, ou clique no bot√£o de execu√ß√£o (√≠cone de 'play') no notebook.

    ![Tabela Externa Pa√≠s](.\images\17-external-table-dim-pais.png)

    ![Tabela Externa Via](.\images\18-external-table-dim-via.png)

    ![Tabela Externa Produto](.\images\19-external-table-dim-product.png)

A cria√ß√£o dessas tabelas externas e a inser√ß√£o de dados s√£o etapas preparat√≥rias para conectar essas tabelas com a ferramenta de visualiza√ß√£o de banco de dados que iremos utilizar, o **DBeaver**. Ao criar tabelas no metastore e fornecer um caminho de localiza√ß√£o, os dados podem ser acessados e gerenciados pelo DBeaver, permitindo visualiza√ß√µes, consultas e outras opera√ß√µes de banco de dados.

Parab√©ns, voc√™ terminou esse laborat√≥rio! üéâ

Voc√™ pode **seguir para o pr√≥ximo Lab**.

## (OPCIONAL) Tarefa 6: An√°lise de dados em Matplotlib

Para realizar a an√°lise das quest√µes propostas no laborat√≥rio 3, agora contamos com nosso dataset tratado e enriquecido, dispon√≠vel atrav√©s da visualiza√ß√£o *`df_exp_enriched`*. Utilizaremos a biblioteca *`matplotlib`* para responder √†s perguntas espec√≠ficas sobre as rela√ß√µes comerciais entre o Brasil e os outros pa√≠ses.

> **Matplotlib** √© uma biblioteca do Python usada para criar gr√°ficos e visualiza√ß√µes de dados. √â como uma caixa de ferramentas para desenhar gr√°ficos e diagramas, tornando mais f√°cil entender e apresentar informa√ß√µes de forma visual.

### **Principais produtos (NCM) exportados e importados no Brasil para os pa√≠ses do Mercosul:**

---

Este c√≥digo em PySpark filtra as exporta√ß√µes do Brasil para os pa√≠ses do Mercosul, agrupa os dados por c√≥digo NCM (c√≥digo de classifica√ß√£o de mercadorias), e conta a frequ√™ncia de cada c√≥digo. Em seguida, seleciona os 10 c√≥digos mais frequentes e converte o resultado para um DataFrame do Pandas. O objetivo √© preparar esses dados para uma visualiza√ß√£o gr√°fica com Matplotlib, destacando os principais produtos exportados e importados pelo Brasil para o Mercosul.

![Contagem de produtos](.\images\20-count-product.png)

O c√≥digo seleciona os nomes correspondentes aos 10 principais c√≥digos NCM de exporta√ß√£o e importa√ß√£o do Brasil para o Mercosul, filtra esses nomes a partir de um DataFrame do PySpark, e converte o resultado em um DataFrame do Pandas para facilitar a an√°lise e visualiza√ß√£o.

![Sele√ß√£o 10 produtos](.\images\21-select-products.png)

O gr√°fico representa a contagem total de exporta√ß√µes e importa√ß√µes para os 10 principais produtos, identificados pelos seus c√≥digos NCM de 2 d√≠gitos, exportados e importados pelo Brasil para os pa√≠ses do Mercosul. O c√≥digo define o tamanho do gr√°fico, as cores das barras, os r√≥tulos dos eixos, o t√≠tulo e a rota√ß√£o dos r√≥tulos no eixo X para uma melhor visualiza√ß√£o. Al√©m disso, uma grade √© adicionada ao eixo Y para facilitar a leitura dos valores.

![Gr√°fico Tabela Produtos](.\images\22-product-export-table.png)

### **Estado brasileiro que mais exportou mercadorias nos √∫ltimos 6 meses:**

---

O c√≥digo filtra as exporta√ß√µes do ano de 2023 entre mar√ßo e agosto, agrupa por estado e calcula o valor total das importa√ß√µes por estado. Os estados s√£o ent√£o ordenados pelo valor total de importa√ß√µes em ordem decrescente, e o resultado √© convertido para um DataFrame do Pandas para an√°lise e visualiza√ß√£o dos estados com o maior volume de importa√ß√µes.

![Exporta√ß√£o e Importa√ß√£o por Regi√£o](.\images\23-rg-import-export.png)

Este c√≥digo usa Matplotlib para criar um gr√°fico de barras do valor total de importa√ß√µes por estado no Brasil, com base nos dados dos √∫ltimos seis meses de 2023. Cada estado √© representado no eixo X, com o valor total de importa√ß√µes no eixo Y, e o gr√°fico √© formatado para facilitar a leitura, r√≥tulos rotacionados e uma grade no eixo Y. O gr√°fico √© finalizado e exibido usando o comando %matplot plt.

![Gr√°fico Exporta√ß√£o e Importa√ß√£o](.\images\24-matplot-region.png)


## Conclus√£o

Neste laborat√≥rio, utilizamos visualiza√ß√µes tempor√°rias no Spark para realizar an√°lises avan√ßadas de dados de exporta√ß√£o e importa√ß√£o do Brasil, utilizando SQL e PySpark para manipular e enriquecer os DataFrames. Implementamos o Star Schema para estruturar as tabelas de forma eficiente, permitindo an√°lises complexas e intuitivas. Criamos tabelas Delta na camada Gold para an√°lise em ferramentas de banco de dados, como o DBeaver, e exploramos rela√ß√µes comerciais com pa√≠ses do Mercosul, identificando os principais produtos negociados e os estados brasileiros com o maior volume de exporta√ß√µes nos √∫ltimos seis meses de 2023. Finalmente, visualizamos nossos resultados utilizando a biblioteca Matplotlib, criando gr√°ficos claros e informativos para apresentar nossas descobertas.
## Autoria

- **Autores** - Thais Henrique, Heloisa Escobar, Isabelle Anjos
- **√öltimo Update Por/Date** - Isabelle Anjos, Jan/2024