# Installing pre-rrequisites on your VM instance 

## Introduction

Once you have completed the VM installation steps in Lab-1, the next steps will go over the installation of the following components:
- Ollama
    - Ollama is an open-source project that serves as a powerful and user-friendly platform for running LLMs on your local machine. It acts as a bridge between the complexities of LLM technology and the desire for an accessible and customizable AI experience.
- Required AI Models and Dependencies
    - Mistral
    - Llama 3
    - nomic-emebed-text


### Step 1: Install Ollama on your instance

![Install Ollama](/ai-edge-rover/images/6_install_ollama.png)

### Step 2: Using Ollama to pull required models: Pulling Mistral

![Install Pulling Mistral](/ai-edge-rover/images/7_pull_mistral.png)

### Step 3: Using Ollama to pull required models: Pulling Llama3

![Install Pulling Llama3](/ai-edge-rover/images/8_pull_llama3.png)

### Step 4: Using Ollama to pull required models: Pulling nomic-embed-text

![Install Pulling Llama3](/ai-edge-rover/images/9_pull_nomic_embed_text.png)


