# Installing pre-requisites on your VM instance 

## Introduction

Once you have completed the VM installation steps in Lab-1, the next steps will go over the installation of the following components:
- Ollama
    - Ollama is an open-source project that serves as a powerful and user-friendly platform for running LLMs on your local machine. It acts as a bridge between the complexities of LLM technology and the desire for an accessible and customizable AI experience.
- Required AI Models and Dependencies
    - Mistral
    - Llama 3
    - nomic-emebed-text


### Step 1: Install Ollama on your instance

![Install Ollama](/edge-cloud/ai-edge-rover/pre_requisites_VM/images/6_install_ollama.png)

### Step 2: Using Ollama to pull required models: Pulling Mistral

![Install Pulling Mistral](/edge-cloud/ai-edge-rover/pre_requisites_VM/images/7_pull_mistral.png)

### Step 3: Using Ollama to pull required models: Pulling Llama3

![Install Pulling Llama3](/edge-cloud/ai-edge-rover/pre_requisites_VM/images/8_pull_llama3.png)

### Step 4: Using Ollama to pull required models: Pulling nomic-embed-text

![Install Pulling Llama3](/edge-cloud/ai-edge-rover/pre_requisites_VM/images/9_pull_nomic_embed_text.png)


