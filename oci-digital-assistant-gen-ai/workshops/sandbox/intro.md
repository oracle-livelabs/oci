Introduction
------------

Oracle Digital Assistant delivers a complete AI platform to create conversational experiences for business applications through text, chat, and voice interfaces.

Generative AI features:
Oracle Digital Assistant has generative AI features that allow users to integrate large language models (LLMs) and other generative capabilities into their digital assistants. In addition, developers can use generative AI to build digital assistants more quickly and efficiently.

Natural language understanding and machine learning:
Oracle Digital Assistant applies deep semantic parsing using natural language processing, natural language understanding (NLU), and custom algorithms to understand common conversations to derive accurate intent and context.

AI-powered voice:
Eliminate reliance on third-party offerings with Oracleâ€™s AI-powered voice. Users can communicate with their business application using voice commands with an assistant that understands their business-specific vocabulary and enables naturally expressive interactions. Give your customers more control of their data by providing end-to-end security and compliance with privacy standards, such as PII and GDPR.

Analytics and insights: 
Gain customer insights through built-in analytics that identify conversational bottlenecks and usage patterns and make data-driven decisions that continually improve the user experience.

Unified conversational experience:
Oracle Digital Assistant unifies single-purpose chatbots into one digital assistant, making it easy for users to interact with multiple systems from one conversation. Conversations are contextual and personalized to individual users and roles.


This 45-minute tutorial shows you how to integrate generative AI into your skill by connecting it to a large language model, or LLM. An LLM is an AI system that has been trained on vast amounts of text data. These models can be trained on various domains to perform a variety of tasks, including audience-specific text summarization and sentiment analysis of chat histories.

By integrating your skill with an LLM, you enable it to not only field a range of user input, but also to respond with context-appropriate answers in a human-like tone. To help the LLM predict the most likely words or phrases for its responses, you send it the appropriate context and instructions in a block of text known as a prompt. In response, the LLM generates a completion, a sequence of words or phrases that it believes are the most probable continuation of the prompt.
